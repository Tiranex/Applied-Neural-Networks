{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Database\n",
    "Source: https://www.kaggle.com/datasets/marcpaulo/connect4-2-step-lookahead-moves-100k?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "      <th>inarow</th>\n",
       "      <th>flat_board</th>\n",
       "      <th>mark</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>#100000012000002100000220000012020102211011</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>#020022001002100220120211011112112221212121</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>#000002000200212011012101222122211212111211</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>#000000000000000000000000010000002002210100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>#000000000000000001000000102020021202121211</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rows  columns  inarow                                   flat_board  mark  \\\n",
       "0     6        7       4  #100000012000002100000220000012020102211011     2   \n",
       "1     6        7       4  #020022001002100220120211011112112221212121     1   \n",
       "2     6        7       4  #000002000200212011012101222122211212111211     2   \n",
       "3     6        7       4  #000000000000000000000000010000002002210100     1   \n",
       "4     6        7       4  #000000000000000001000000102020021202121211     1   \n",
       "\n",
       "   action  \n",
       "0       4  \n",
       "1       3  \n",
       "2       4  \n",
       "3       2  \n",
       "4       4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./2stepLA_moves.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/code/marcpaulo/connect4-convnet-imitates-2-stepla-agent/notebook#Connect4:-ConvNet-imitates-2-Step-Lookahead-Agent\n",
    "# First, remove the '#' initial character\n",
    "flat_boards = df['flat_board'].map(lambda b: b[1:])\n",
    "# Turn the values from strings into lists of integers\n",
    "flat_boards = flat_boards.map(lambda b: [int(bb) for bb in b])\n",
    "# Turn the lists into Numpy arrays and reshape them\n",
    "rows = df['rows'].unique()[0]\n",
    "columns = df['columns'].unique()[0]\n",
    "numpy_2d_boards_ = flat_boards.map(lambda b: np.array(b).reshape(rows, columns))\n",
    "# Stack the arrays to have the desired shape\n",
    "numpy_2d_boards = np.stack(numpy_2d_boards_.values)\n",
    "\n",
    "# New encoding: {0: empty, 1: active player, -1: opponent}\n",
    "for board, mark in zip(numpy_2d_boards, df['mark']):\n",
    "    if mark == 1:\n",
    "        board[board == 2] = -1\n",
    "    else:  # a.k.a mark == 2:\n",
    "        board[board == 1] = -1\n",
    "        board[board == 2] = 1\n",
    "\n",
    "numpy_2d_boards = numpy_2d_boards.reshape((len(numpy_2d_boards), rows, columns, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "train_size = 90000\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_data = Dataset.from_tensor_slices((numpy_2d_boards[0:train_size], df['action'].values[0:train_size]))\n",
    "val_data = Dataset.from_tensor_slices((numpy_2d_boards[train_size:train_size+val_size], df['action'].values[train_size:train_size+val_size]))\n",
    "test_data = Dataset.from_tensor_slices((numpy_2d_boards[train_size+val_size:train_size+val_size+test_size], df['action'].values[train_size+val_size:train_size+val_size+test_size]))\n",
    "\n",
    "train_data = train_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_data = val_data.batch(BATCH_SIZE)\n",
    "test_data = test_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = (6,7, 1)\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, (2, 2), activation='relu', input_shape=input_shape),\n",
    "    layers.Conv2D(128, (2, 2), activation='relu'),\n",
    "    layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'InvocationException'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mf:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\pydot\\core.py:1753\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     stdout_data, stderr_data, process \u001b[38;5;241m=\u001b[39m \u001b[43mcall_graphviz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mf:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\pydot\\core.py:133\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m program_with_args \u001b[38;5;241m=\u001b[39m [program] \u001b[38;5;241m+\u001b[39m arguments\n\u001b[1;32m--> 133\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[0;32m    134\u001b[0m     program_with_args,\n\u001b[0;32m    135\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m    136\u001b[0m     cwd\u001b[38;5;241m=\u001b[39mworking_dir,\n\u001b[0;32m    137\u001b[0m     shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    138\u001b[0m     stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[0;32m    139\u001b[0m     stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    142\u001b[0m stdout_data, stderr_data \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py:947\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    945\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py:1416\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1416\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1418\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mf:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\utils\\vis_utils.py:57\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\pydot\\core.py:1762\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1761\u001b[0m     args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in path.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(prog\u001b[38;5;241m=\u001b[39mprog)\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_layer_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrankdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\utils\\vis_utils.py:451\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     )\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_graphviz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    452\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor plot_model to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m     )\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing\u001b[39;00m\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;66;03m# notebook tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[1;32mf:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\utils\\vis_utils.py:59\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m     pydot\u001b[38;5;241m.\u001b[39mDot\u001b[38;5;241m.\u001b[39mcreate(pydot\u001b[38;5;241m.\u001b[39mDot())\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInvocationException\u001b[49m):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'InvocationException'"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, dpi=300, show_layer_activations=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From f:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1407/1407 [==============================] - 11s 6ms/step - loss: 1.1915 - accuracy: 0.5596 - val_loss: 0.9499 - val_accuracy: 0.6556\n",
      "Epoch 2/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8086 - accuracy: 0.7070 - val_loss: 0.7446 - val_accuracy: 0.7320\n",
      "Epoch 3/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.6743 - accuracy: 0.7555 - val_loss: 0.7000 - val_accuracy: 0.7490\n",
      "Epoch 4/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.6011 - accuracy: 0.7802 - val_loss: 0.6766 - val_accuracy: 0.7626\n",
      "Epoch 5/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5451 - accuracy: 0.7996 - val_loss: 0.6628 - val_accuracy: 0.7672\n",
      "Epoch 6/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.5006 - accuracy: 0.8163 - val_loss: 0.6617 - val_accuracy: 0.7728\n",
      "Epoch 7/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4621 - accuracy: 0.8298 - val_loss: 0.6644 - val_accuracy: 0.7740\n",
      "Epoch 8/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4280 - accuracy: 0.8425 - val_loss: 0.6776 - val_accuracy: 0.7764\n",
      "Epoch 9/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3995 - accuracy: 0.8531 - val_loss: 0.6987 - val_accuracy: 0.7812\n",
      "Epoch 10/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3713 - accuracy: 0.8637 - val_loss: 0.7289 - val_accuracy: 0.7808\n",
      "Epoch 11/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3486 - accuracy: 0.8726 - val_loss: 0.7498 - val_accuracy: 0.7810\n",
      "Epoch 12/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.3277 - accuracy: 0.8791 - val_loss: 0.7736 - val_accuracy: 0.7776\n",
      "Epoch 13/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3089 - accuracy: 0.8868 - val_loss: 0.8011 - val_accuracy: 0.7774\n",
      "Epoch 14/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2920 - accuracy: 0.8921 - val_loss: 0.8449 - val_accuracy: 0.7722\n",
      "Epoch 15/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.2782 - accuracy: 0.8972 - val_loss: 0.8935 - val_accuracy: 0.7702\n",
      "Epoch 16/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.2628 - accuracy: 0.9023 - val_loss: 0.9299 - val_accuracy: 0.7688\n",
      "Epoch 17/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2534 - accuracy: 0.9068 - val_loss: 0.9816 - val_accuracy: 0.7766\n",
      "Epoch 18/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2371 - accuracy: 0.9126 - val_loss: 1.0153 - val_accuracy: 0.7768\n",
      "Epoch 19/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2273 - accuracy: 0.9160 - val_loss: 1.0275 - val_accuracy: 0.7768\n",
      "Epoch 20/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.2205 - accuracy: 0.9174 - val_loss: 1.0791 - val_accuracy: 0.7724\n",
      "Epoch 21/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.2082 - accuracy: 0.9222 - val_loss: 1.0911 - val_accuracy: 0.7708\n",
      "Epoch 22/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2007 - accuracy: 0.9239 - val_loss: 1.1292 - val_accuracy: 0.7666\n",
      "Epoch 23/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1945 - accuracy: 0.9271 - val_loss: 1.1551 - val_accuracy: 0.7714\n",
      "Epoch 24/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1851 - accuracy: 0.9308 - val_loss: 1.2156 - val_accuracy: 0.7668\n",
      "Epoch 25/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1822 - accuracy: 0.9323 - val_loss: 1.2417 - val_accuracy: 0.7702\n",
      "Epoch 26/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1722 - accuracy: 0.9361 - val_loss: 1.2225 - val_accuracy: 0.7662\n",
      "Epoch 27/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1682 - accuracy: 0.9382 - val_loss: 1.2823 - val_accuracy: 0.7738\n",
      "Epoch 28/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1626 - accuracy: 0.9397 - val_loss: 1.3142 - val_accuracy: 0.7702\n",
      "Epoch 29/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1552 - accuracy: 0.9422 - val_loss: 1.3165 - val_accuracy: 0.7664\n",
      "Epoch 30/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1585 - accuracy: 0.9416 - val_loss: 1.3873 - val_accuracy: 0.7694\n",
      "Epoch 31/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.1514 - accuracy: 0.9432 - val_loss: 1.3994 - val_accuracy: 0.7678\n",
      "Epoch 32/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1429 - accuracy: 0.9463 - val_loss: 1.4175 - val_accuracy: 0.7702\n",
      "Epoch 33/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1362 - accuracy: 0.9490 - val_loss: 1.4436 - val_accuracy: 0.7644\n",
      "Epoch 34/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1411 - accuracy: 0.9473 - val_loss: 1.4786 - val_accuracy: 0.7666\n",
      "Epoch 35/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1351 - accuracy: 0.9497 - val_loss: 1.5035 - val_accuracy: 0.7720\n",
      "Epoch 36/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1304 - accuracy: 0.9511 - val_loss: 1.5139 - val_accuracy: 0.7676\n",
      "Epoch 37/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1300 - accuracy: 0.9517 - val_loss: 1.5393 - val_accuracy: 0.7618\n",
      "Epoch 38/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1269 - accuracy: 0.9525 - val_loss: 1.6238 - val_accuracy: 0.7618\n",
      "Epoch 39/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.1212 - accuracy: 0.9554 - val_loss: 1.6413 - val_accuracy: 0.7642\n",
      "Epoch 40/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.1221 - accuracy: 0.9549 - val_loss: 1.6710 - val_accuracy: 0.7690\n",
      "Epoch 41/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1201 - accuracy: 0.9551 - val_loss: 1.5613 - val_accuracy: 0.7744\n",
      "Epoch 42/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1155 - accuracy: 0.9568 - val_loss: 1.5925 - val_accuracy: 0.7752\n",
      "Epoch 43/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1145 - accuracy: 0.9574 - val_loss: 1.6109 - val_accuracy: 0.7624\n",
      "Epoch 44/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1095 - accuracy: 0.9590 - val_loss: 1.6834 - val_accuracy: 0.7618\n",
      "Epoch 45/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1124 - accuracy: 0.9587 - val_loss: 1.6557 - val_accuracy: 0.7654\n",
      "Epoch 46/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1067 - accuracy: 0.9609 - val_loss: 1.6996 - val_accuracy: 0.7688\n",
      "Epoch 47/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1059 - accuracy: 0.9614 - val_loss: 1.7595 - val_accuracy: 0.7640\n",
      "Epoch 48/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1072 - accuracy: 0.9605 - val_loss: 1.6657 - val_accuracy: 0.7748\n",
      "Epoch 49/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1043 - accuracy: 0.9617 - val_loss: 1.7390 - val_accuracy: 0.7690\n",
      "Epoch 50/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1006 - accuracy: 0.9627 - val_loss: 1.7480 - val_accuracy: 0.7706\n",
      "Epoch 51/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1017 - accuracy: 0.9622 - val_loss: 1.7815 - val_accuracy: 0.7698\n",
      "Epoch 52/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0980 - accuracy: 0.9643 - val_loss: 1.7309 - val_accuracy: 0.7658\n",
      "Epoch 53/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0975 - accuracy: 0.9649 - val_loss: 1.8144 - val_accuracy: 0.7618\n",
      "Epoch 54/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0968 - accuracy: 0.9651 - val_loss: 1.7990 - val_accuracy: 0.7666\n",
      "Epoch 55/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0944 - accuracy: 0.9659 - val_loss: 1.8195 - val_accuracy: 0.7680\n",
      "Epoch 56/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0917 - accuracy: 0.9665 - val_loss: 1.8259 - val_accuracy: 0.7722\n",
      "Epoch 57/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0869 - accuracy: 0.9674 - val_loss: 1.8733 - val_accuracy: 0.7692\n",
      "Epoch 58/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0985 - accuracy: 0.9648 - val_loss: 1.7737 - val_accuracy: 0.7694\n",
      "Epoch 59/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0857 - accuracy: 0.9684 - val_loss: 1.9695 - val_accuracy: 0.7690\n",
      "Epoch 60/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0863 - accuracy: 0.9691 - val_loss: 1.9085 - val_accuracy: 0.7692\n",
      "Epoch 61/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0883 - accuracy: 0.9682 - val_loss: 1.8305 - val_accuracy: 0.7722\n",
      "Epoch 62/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0851 - accuracy: 0.9687 - val_loss: 1.8906 - val_accuracy: 0.7742\n",
      "Epoch 63/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0869 - accuracy: 0.9686 - val_loss: 1.8759 - val_accuracy: 0.7708\n",
      "Epoch 64/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0821 - accuracy: 0.9708 - val_loss: 1.9903 - val_accuracy: 0.7656\n",
      "Epoch 65/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 1.9771 - val_accuracy: 0.7632\n",
      "Epoch 66/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0838 - accuracy: 0.9701 - val_loss: 1.9771 - val_accuracy: 0.7696\n",
      "Epoch 67/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0779 - accuracy: 0.9715 - val_loss: 1.9539 - val_accuracy: 0.7744\n",
      "Epoch 68/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0829 - accuracy: 0.9701 - val_loss: 1.9188 - val_accuracy: 0.7726\n",
      "Epoch 69/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0788 - accuracy: 0.9716 - val_loss: 1.8945 - val_accuracy: 0.7764\n",
      "Epoch 70/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0780 - accuracy: 0.9719 - val_loss: 1.9443 - val_accuracy: 0.7682\n",
      "Epoch 71/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0787 - accuracy: 0.9722 - val_loss: 1.9901 - val_accuracy: 0.7698\n",
      "Epoch 72/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0767 - accuracy: 0.9723 - val_loss: 2.0017 - val_accuracy: 0.7704\n",
      "Epoch 73/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0765 - accuracy: 0.9728 - val_loss: 1.9535 - val_accuracy: 0.7704\n",
      "Epoch 74/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 1.9940 - val_accuracy: 0.7664\n",
      "Epoch 75/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0739 - accuracy: 0.9739 - val_loss: 1.9701 - val_accuracy: 0.7694\n",
      "Epoch 76/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0690 - accuracy: 0.9752 - val_loss: 2.0413 - val_accuracy: 0.7684\n",
      "Epoch 77/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0753 - accuracy: 0.9732 - val_loss: 2.0585 - val_accuracy: 0.7708\n",
      "Epoch 78/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0725 - accuracy: 0.9744 - val_loss: 2.0370 - val_accuracy: 0.7742\n",
      "Epoch 79/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0714 - accuracy: 0.9741 - val_loss: 2.1092 - val_accuracy: 0.7720\n",
      "Epoch 80/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0714 - accuracy: 0.9746 - val_loss: 2.0744 - val_accuracy: 0.7696\n",
      "Epoch 81/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0725 - accuracy: 0.9744 - val_loss: 2.1572 - val_accuracy: 0.7690\n",
      "Epoch 82/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 2.1739 - val_accuracy: 0.7674\n",
      "Epoch 83/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0672 - accuracy: 0.9758 - val_loss: 2.0768 - val_accuracy: 0.7744\n",
      "Epoch 84/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0744 - accuracy: 0.9740 - val_loss: 2.0877 - val_accuracy: 0.7682\n",
      "Epoch 85/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0653 - accuracy: 0.9767 - val_loss: 2.1343 - val_accuracy: 0.7674\n",
      "Epoch 86/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 2.1170 - val_accuracy: 0.7716\n",
      "Epoch 87/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0667 - accuracy: 0.9765 - val_loss: 2.1653 - val_accuracy: 0.7750\n",
      "Epoch 88/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0684 - accuracy: 0.9751 - val_loss: 2.1337 - val_accuracy: 0.7686\n",
      "Epoch 89/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0697 - accuracy: 0.9756 - val_loss: 2.2133 - val_accuracy: 0.7712\n",
      "Epoch 90/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 2.2052 - val_accuracy: 0.7726\n",
      "Epoch 91/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0606 - accuracy: 0.9784 - val_loss: 2.2107 - val_accuracy: 0.7678\n",
      "Epoch 92/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0717 - accuracy: 0.9749 - val_loss: 2.1814 - val_accuracy: 0.7660\n",
      "Epoch 93/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0621 - accuracy: 0.9778 - val_loss: 2.2036 - val_accuracy: 0.7682\n",
      "Epoch 94/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0618 - accuracy: 0.9777 - val_loss: 2.2465 - val_accuracy: 0.7732\n",
      "Epoch 95/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0620 - accuracy: 0.9780 - val_loss: 2.2717 - val_accuracy: 0.7694\n",
      "Epoch 96/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 2.1904 - val_accuracy: 0.7796\n",
      "Epoch 97/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0586 - accuracy: 0.9789 - val_loss: 2.2517 - val_accuracy: 0.7738\n",
      "Epoch 98/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0660 - accuracy: 0.9770 - val_loss: 2.1583 - val_accuracy: 0.7756\n",
      "Epoch 99/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0608 - accuracy: 0.9785 - val_loss: 2.2732 - val_accuracy: 0.7718\n",
      "Epoch 100/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0626 - accuracy: 0.9780 - val_loss: 2.2568 - val_accuracy: 0.7656\n",
      "Epoch 101/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0588 - accuracy: 0.9793 - val_loss: 2.2751 - val_accuracy: 0.7696\n",
      "Epoch 102/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0630 - accuracy: 0.9778 - val_loss: 2.3204 - val_accuracy: 0.7720\n",
      "Epoch 103/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0602 - accuracy: 0.9785 - val_loss: 2.2656 - val_accuracy: 0.7716\n",
      "Epoch 104/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 2.3660 - val_accuracy: 0.7670\n",
      "Epoch 105/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 2.2874 - val_accuracy: 0.7742\n",
      "Epoch 106/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 2.3146 - val_accuracy: 0.7744\n",
      "Epoch 107/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0608 - accuracy: 0.9795 - val_loss: 2.2929 - val_accuracy: 0.7710\n",
      "Epoch 108/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0606 - accuracy: 0.9791 - val_loss: 2.2229 - val_accuracy: 0.7792\n",
      "Epoch 109/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0565 - accuracy: 0.9806 - val_loss: 2.2442 - val_accuracy: 0.7764\n",
      "Epoch 110/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0575 - accuracy: 0.9804 - val_loss: 2.3362 - val_accuracy: 0.7674\n",
      "Epoch 111/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0604 - accuracy: 0.9791 - val_loss: 2.3129 - val_accuracy: 0.7722\n",
      "Epoch 112/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0564 - accuracy: 0.9805 - val_loss: 2.4075 - val_accuracy: 0.7750\n",
      "Epoch 113/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 2.3588 - val_accuracy: 0.7758\n",
      "Epoch 114/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 2.3559 - val_accuracy: 0.7758\n",
      "Epoch 115/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 2.3409 - val_accuracy: 0.7780\n",
      "Epoch 116/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 2.4141 - val_accuracy: 0.7778\n",
      "Epoch 117/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 2.3941 - val_accuracy: 0.7782\n",
      "Epoch 118/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0549 - accuracy: 0.9809 - val_loss: 2.4158 - val_accuracy: 0.7790\n",
      "Epoch 119/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 2.3728 - val_accuracy: 0.7756\n",
      "Epoch 120/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0520 - accuracy: 0.9816 - val_loss: 2.5056 - val_accuracy: 0.7722\n",
      "Epoch 121/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0536 - accuracy: 0.9819 - val_loss: 2.5265 - val_accuracy: 0.7742\n",
      "Epoch 122/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 2.4870 - val_accuracy: 0.7746\n",
      "Epoch 123/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0528 - accuracy: 0.9813 - val_loss: 2.3377 - val_accuracy: 0.7736\n",
      "Epoch 124/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0521 - accuracy: 0.9822 - val_loss: 2.4666 - val_accuracy: 0.7760\n",
      "Epoch 125/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 2.4279 - val_accuracy: 0.7772\n",
      "Epoch 126/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0551 - accuracy: 0.9811 - val_loss: 2.4259 - val_accuracy: 0.7758\n",
      "Epoch 127/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 2.4122 - val_accuracy: 0.7796\n",
      "Epoch 128/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 2.4454 - val_accuracy: 0.7758\n",
      "Epoch 129/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0617 - accuracy: 0.9792 - val_loss: 2.3752 - val_accuracy: 0.7810\n",
      "Epoch 130/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 2.5261 - val_accuracy: 0.7718\n",
      "Epoch 131/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 2.4913 - val_accuracy: 0.7734\n",
      "Epoch 132/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 2.5412 - val_accuracy: 0.7754\n",
      "Epoch 133/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0518 - accuracy: 0.9824 - val_loss: 2.4976 - val_accuracy: 0.7736\n",
      "Epoch 134/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0492 - accuracy: 0.9827 - val_loss: 2.4820 - val_accuracy: 0.7790\n",
      "Epoch 135/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 2.3763 - val_accuracy: 0.7716\n",
      "Epoch 136/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0487 - accuracy: 0.9835 - val_loss: 2.5078 - val_accuracy: 0.7744\n",
      "Epoch 137/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0511 - accuracy: 0.9828 - val_loss: 2.4677 - val_accuracy: 0.7800\n",
      "Epoch 138/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0498 - accuracy: 0.9831 - val_loss: 2.4522 - val_accuracy: 0.7758\n",
      "Epoch 139/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0488 - accuracy: 0.9829 - val_loss: 2.5139 - val_accuracy: 0.7766\n",
      "Epoch 140/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0505 - accuracy: 0.9827 - val_loss: 2.4793 - val_accuracy: 0.7750\n",
      "Epoch 141/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 2.5636 - val_accuracy: 0.7728\n",
      "Epoch 142/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0523 - accuracy: 0.9818 - val_loss: 2.4912 - val_accuracy: 0.7774\n",
      "Epoch 143/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0520 - accuracy: 0.9822 - val_loss: 2.5061 - val_accuracy: 0.7786\n",
      "Epoch 144/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 2.4881 - val_accuracy: 0.7818\n",
      "Epoch 145/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 2.5369 - val_accuracy: 0.7812\n",
      "Epoch 146/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0457 - accuracy: 0.9844 - val_loss: 2.6440 - val_accuracy: 0.7730\n",
      "Epoch 147/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0509 - accuracy: 0.9831 - val_loss: 2.5958 - val_accuracy: 0.7778\n",
      "Epoch 148/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0475 - accuracy: 0.9838 - val_loss: 2.5586 - val_accuracy: 0.7724\n",
      "Epoch 149/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 2.6653 - val_accuracy: 0.7742\n",
      "Epoch 150/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0479 - accuracy: 0.9837 - val_loss: 2.6308 - val_accuracy: 0.7742\n",
      "Epoch 151/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 2.6409 - val_accuracy: 0.7770\n",
      "Epoch 152/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0452 - accuracy: 0.9841 - val_loss: 2.6961 - val_accuracy: 0.7806\n",
      "Epoch 153/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 2.6770 - val_accuracy: 0.7764\n",
      "Epoch 154/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0472 - accuracy: 0.9840 - val_loss: 2.7364 - val_accuracy: 0.7806\n",
      "Epoch 155/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 2.6651 - val_accuracy: 0.7758\n",
      "Epoch 156/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0461 - accuracy: 0.9836 - val_loss: 2.6627 - val_accuracy: 0.7826\n",
      "Epoch 157/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 2.6859 - val_accuracy: 0.7824\n",
      "Epoch 158/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0466 - accuracy: 0.9843 - val_loss: 2.6810 - val_accuracy: 0.7758\n",
      "Epoch 159/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 2.7150 - val_accuracy: 0.7764\n",
      "Epoch 160/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0469 - accuracy: 0.9843 - val_loss: 2.6701 - val_accuracy: 0.7810\n",
      "Epoch 161/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0454 - accuracy: 0.9843 - val_loss: 2.8078 - val_accuracy: 0.7778\n",
      "Epoch 162/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 2.7368 - val_accuracy: 0.7774\n",
      "Epoch 163/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 2.7032 - val_accuracy: 0.7756\n",
      "Epoch 164/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0440 - accuracy: 0.9850 - val_loss: 2.7687 - val_accuracy: 0.7792\n",
      "Epoch 165/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 2.7598 - val_accuracy: 0.7778\n",
      "Epoch 166/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0472 - accuracy: 0.9839 - val_loss: 2.7657 - val_accuracy: 0.7702\n",
      "Epoch 167/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 2.8021 - val_accuracy: 0.7776\n",
      "Epoch 168/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0465 - accuracy: 0.9845 - val_loss: 2.6896 - val_accuracy: 0.7726\n",
      "Epoch 169/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0438 - accuracy: 0.9849 - val_loss: 2.7679 - val_accuracy: 0.7772\n",
      "Epoch 170/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0449 - accuracy: 0.9845 - val_loss: 2.8273 - val_accuracy: 0.7786\n",
      "Epoch 171/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0456 - accuracy: 0.9845 - val_loss: 2.7856 - val_accuracy: 0.7738\n",
      "Epoch 172/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 2.9179 - val_accuracy: 0.7760\n",
      "Epoch 173/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0430 - accuracy: 0.9856 - val_loss: 2.7884 - val_accuracy: 0.7784\n",
      "Epoch 174/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 2.8735 - val_accuracy: 0.7790\n",
      "Epoch 175/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0416 - accuracy: 0.9858 - val_loss: 2.8047 - val_accuracy: 0.7718\n",
      "Epoch 176/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 2.8776 - val_accuracy: 0.7756\n",
      "Epoch 177/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0411 - accuracy: 0.9858 - val_loss: 2.8267 - val_accuracy: 0.7798\n",
      "Epoch 178/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 2.7664 - val_accuracy: 0.7788\n",
      "Epoch 179/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 2.8094 - val_accuracy: 0.7768\n",
      "Epoch 180/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0450 - accuracy: 0.9850 - val_loss: 2.7735 - val_accuracy: 0.7730\n",
      "Epoch 181/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0459 - accuracy: 0.9845 - val_loss: 2.7735 - val_accuracy: 0.7756\n",
      "Epoch 182/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 2.8854 - val_accuracy: 0.7668\n",
      "Epoch 183/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0462 - accuracy: 0.9846 - val_loss: 3.0060 - val_accuracy: 0.7728\n",
      "Epoch 184/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 3.0184 - val_accuracy: 0.7722\n",
      "Epoch 185/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0437 - accuracy: 0.9850 - val_loss: 2.8885 - val_accuracy: 0.7748\n",
      "Epoch 186/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 2.9119 - val_accuracy: 0.7776\n",
      "Epoch 187/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 2.9107 - val_accuracy: 0.7762\n",
      "Epoch 188/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 2.9681 - val_accuracy: 0.7786\n",
      "Epoch 189/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 3.0110 - val_accuracy: 0.7754\n",
      "Epoch 190/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 2.9182 - val_accuracy: 0.7776\n",
      "Epoch 191/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 2.8904 - val_accuracy: 0.7750\n",
      "Epoch 192/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 2.8716 - val_accuracy: 0.7806\n",
      "Epoch 193/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 2.9333 - val_accuracy: 0.7800\n",
      "Epoch 194/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 2.8309 - val_accuracy: 0.7772\n",
      "Epoch 195/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 2.9107 - val_accuracy: 0.7806\n",
      "Epoch 196/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 2.8448 - val_accuracy: 0.7774\n",
      "Epoch 197/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0416 - accuracy: 0.9857 - val_loss: 2.9692 - val_accuracy: 0.7724\n",
      "Epoch 198/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 2.9442 - val_accuracy: 0.7754\n",
      "Epoch 199/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0425 - accuracy: 0.9856 - val_loss: 2.9957 - val_accuracy: 0.7764\n",
      "Epoch 200/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 3.0860 - val_accuracy: 0.7714\n",
      "Epoch 201/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0480 - accuracy: 0.9843 - val_loss: 2.8862 - val_accuracy: 0.7810\n",
      "Epoch 202/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 2.9088 - val_accuracy: 0.7654\n",
      "Epoch 203/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 3.0264 - val_accuracy: 0.7758\n",
      "Epoch 204/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0410 - accuracy: 0.9862 - val_loss: 2.9398 - val_accuracy: 0.7784\n",
      "Epoch 205/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0410 - accuracy: 0.9864 - val_loss: 2.9271 - val_accuracy: 0.7738\n",
      "Epoch 206/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0407 - accuracy: 0.9860 - val_loss: 2.9884 - val_accuracy: 0.7770\n",
      "Epoch 207/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 3.0063 - val_accuracy: 0.7768\n",
      "Epoch 208/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 3.0024 - val_accuracy: 0.7762\n",
      "Epoch 209/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 3.0557 - val_accuracy: 0.7770\n",
      "Epoch 210/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 3.1226 - val_accuracy: 0.7766\n",
      "Epoch 211/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 3.1203 - val_accuracy: 0.7758\n",
      "Epoch 212/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 3.1185 - val_accuracy: 0.7746\n",
      "Epoch 213/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0425 - accuracy: 0.9857 - val_loss: 3.2022 - val_accuracy: 0.7698\n",
      "Epoch 214/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 3.0725 - val_accuracy: 0.7794\n",
      "Epoch 215/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 3.0093 - val_accuracy: 0.7774\n",
      "Epoch 216/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0364 - accuracy: 0.9876 - val_loss: 3.2666 - val_accuracy: 0.7686\n",
      "Epoch 217/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 3.1481 - val_accuracy: 0.7728\n",
      "Epoch 218/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 3.1722 - val_accuracy: 0.7758\n",
      "Epoch 219/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 3.1444 - val_accuracy: 0.7754\n",
      "Epoch 220/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 3.1875 - val_accuracy: 0.7730\n",
      "Epoch 221/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 3.2492 - val_accuracy: 0.7674\n",
      "Epoch 222/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 3.1347 - val_accuracy: 0.7672\n",
      "Epoch 223/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 3.1735 - val_accuracy: 0.7732\n",
      "Epoch 224/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 3.3408 - val_accuracy: 0.7744\n",
      "Epoch 225/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 3.1422 - val_accuracy: 0.7714\n",
      "Epoch 226/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 3.1422 - val_accuracy: 0.7734\n",
      "Epoch 227/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 3.1968 - val_accuracy: 0.7778\n",
      "Epoch 228/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 3.2481 - val_accuracy: 0.7744\n",
      "Epoch 229/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0418 - accuracy: 0.9864 - val_loss: 3.2096 - val_accuracy: 0.7734\n",
      "Epoch 230/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0387 - accuracy: 0.9871 - val_loss: 3.1492 - val_accuracy: 0.7692\n",
      "Epoch 231/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 3.2472 - val_accuracy: 0.7728\n",
      "Epoch 232/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 3.1541 - val_accuracy: 0.7788\n",
      "Epoch 233/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 3.2708 - val_accuracy: 0.7766\n",
      "Epoch 234/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 3.1440 - val_accuracy: 0.7732\n",
      "Epoch 235/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 3.2426 - val_accuracy: 0.7734\n",
      "Epoch 236/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 3.2083 - val_accuracy: 0.7732\n",
      "Epoch 237/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 3.2830 - val_accuracy: 0.7816\n",
      "Epoch 238/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 3.3210 - val_accuracy: 0.7742\n",
      "Epoch 239/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 3.3918 - val_accuracy: 0.7724\n",
      "Epoch 240/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0404 - accuracy: 0.9863 - val_loss: 3.3730 - val_accuracy: 0.7706\n",
      "Epoch 241/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 3.3877 - val_accuracy: 0.7716\n",
      "Epoch 242/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 3.3598 - val_accuracy: 0.7730\n",
      "Epoch 243/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 3.2426 - val_accuracy: 0.7748\n",
      "Epoch 244/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 3.1802 - val_accuracy: 0.7766\n",
      "Epoch 245/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 3.2972 - val_accuracy: 0.7812\n",
      "Epoch 246/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 3.3595 - val_accuracy: 0.7754\n",
      "Epoch 247/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 3.2522 - val_accuracy: 0.7754\n",
      "Epoch 248/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 3.3386 - val_accuracy: 0.7766\n",
      "Epoch 249/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0377 - accuracy: 0.9871 - val_loss: 3.2772 - val_accuracy: 0.7720\n",
      "Epoch 250/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 3.3768 - val_accuracy: 0.7792\n",
      "Epoch 251/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 3.2062 - val_accuracy: 0.7780\n",
      "Epoch 252/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 3.2172 - val_accuracy: 0.7776\n",
      "Epoch 253/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 3.2756 - val_accuracy: 0.7846\n",
      "Epoch 254/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 3.2776 - val_accuracy: 0.7784\n",
      "Epoch 255/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 3.3137 - val_accuracy: 0.7802\n",
      "Epoch 256/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 3.2942 - val_accuracy: 0.7784\n",
      "Epoch 257/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 3.1851 - val_accuracy: 0.7762\n",
      "Epoch 258/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 3.2696 - val_accuracy: 0.7788\n",
      "Epoch 259/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 3.2546 - val_accuracy: 0.7818\n",
      "Epoch 260/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 3.3356 - val_accuracy: 0.7772\n",
      "Epoch 261/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 3.3990 - val_accuracy: 0.7734\n",
      "Epoch 262/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 3.2200 - val_accuracy: 0.7754\n",
      "Epoch 263/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 3.2078 - val_accuracy: 0.7804\n",
      "Epoch 264/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 3.3445 - val_accuracy: 0.7826\n",
      "Epoch 265/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 3.2504 - val_accuracy: 0.7838\n",
      "Epoch 266/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0422 - accuracy: 0.9863 - val_loss: 3.3305 - val_accuracy: 0.7798\n",
      "Epoch 267/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 3.3815 - val_accuracy: 0.7800\n",
      "Epoch 268/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 3.4811 - val_accuracy: 0.7776\n",
      "Epoch 269/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 3.3767 - val_accuracy: 0.7756\n",
      "Epoch 270/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0358 - accuracy: 0.9886 - val_loss: 3.4228 - val_accuracy: 0.7758\n",
      "Epoch 271/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 3.4085 - val_accuracy: 0.7778\n",
      "Epoch 272/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 3.5235 - val_accuracy: 0.7770\n",
      "Epoch 273/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 3.4868 - val_accuracy: 0.7762\n",
      "Epoch 274/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 3.5257 - val_accuracy: 0.7778\n",
      "Epoch 275/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 3.5137 - val_accuracy: 0.7768\n",
      "Epoch 276/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 3.4787 - val_accuracy: 0.7774\n",
      "Epoch 277/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 3.5838 - val_accuracy: 0.7816\n",
      "Epoch 278/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 3.4453 - val_accuracy: 0.7802\n",
      "Epoch 279/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 3.5033 - val_accuracy: 0.7774\n",
      "Epoch 280/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 3.5106 - val_accuracy: 0.7776\n",
      "Epoch 281/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 3.5829 - val_accuracy: 0.7734\n",
      "Epoch 282/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 3.5996 - val_accuracy: 0.7758\n",
      "Epoch 283/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0349 - accuracy: 0.9886 - val_loss: 3.4114 - val_accuracy: 0.7754\n",
      "Epoch 284/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 3.4495 - val_accuracy: 0.7750\n",
      "Epoch 285/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 3.5945 - val_accuracy: 0.7754\n",
      "Epoch 286/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 3.5147 - val_accuracy: 0.7792\n",
      "Epoch 287/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 3.5831 - val_accuracy: 0.7810\n",
      "Epoch 288/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0376 - accuracy: 0.9880 - val_loss: 3.5201 - val_accuracy: 0.7800\n",
      "Epoch 289/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0396 - accuracy: 0.9871 - val_loss: 3.4911 - val_accuracy: 0.7772\n",
      "Epoch 290/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 3.6123 - val_accuracy: 0.7768\n",
      "Epoch 291/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 3.5314 - val_accuracy: 0.7792\n",
      "Epoch 292/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 3.5908 - val_accuracy: 0.7756\n",
      "Epoch 293/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 3.5901 - val_accuracy: 0.7794\n",
      "Epoch 294/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 3.6409 - val_accuracy: 0.7782\n",
      "Epoch 295/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 3.7355 - val_accuracy: 0.7712\n",
      "Epoch 296/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0404 - accuracy: 0.9871 - val_loss: 3.6611 - val_accuracy: 0.7740\n",
      "Epoch 297/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0295 - accuracy: 0.9901 - val_loss: 3.6099 - val_accuracy: 0.7798\n",
      "Epoch 298/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 3.6083 - val_accuracy: 0.7788\n",
      "Epoch 299/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 3.5201 - val_accuracy: 0.7790\n",
      "Epoch 300/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 3.7124 - val_accuracy: 0.7778\n",
      "Epoch 301/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0409 - accuracy: 0.9875 - val_loss: 3.6015 - val_accuracy: 0.7796\n",
      "Epoch 302/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 3.7555 - val_accuracy: 0.7746\n",
      "Epoch 303/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 3.5675 - val_accuracy: 0.7778\n",
      "Epoch 304/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 3.6375 - val_accuracy: 0.7782\n",
      "Epoch 305/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 3.5300 - val_accuracy: 0.7782\n",
      "Epoch 306/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 3.5332 - val_accuracy: 0.7760\n",
      "Epoch 307/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 3.7209 - val_accuracy: 0.7726\n",
      "Epoch 308/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 3.6371 - val_accuracy: 0.7788\n",
      "Epoch 309/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 3.6391 - val_accuracy: 0.7800\n",
      "Epoch 310/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 3.5321 - val_accuracy: 0.7768\n",
      "Epoch 311/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 3.5195 - val_accuracy: 0.7798\n",
      "Epoch 312/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 3.6651 - val_accuracy: 0.7796\n",
      "Epoch 313/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 3.6176 - val_accuracy: 0.7770\n",
      "Epoch 314/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 3.4354 - val_accuracy: 0.7814\n",
      "Epoch 315/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 3.5570 - val_accuracy: 0.7786\n",
      "Epoch 316/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 3.7457 - val_accuracy: 0.7820\n",
      "Epoch 317/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 3.6821 - val_accuracy: 0.7782\n",
      "Epoch 318/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 3.6971 - val_accuracy: 0.7786\n",
      "Epoch 319/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 3.8826 - val_accuracy: 0.7774\n",
      "Epoch 320/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 3.6856 - val_accuracy: 0.7794\n",
      "Epoch 321/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 3.6553 - val_accuracy: 0.7784\n",
      "Epoch 322/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 3.8195 - val_accuracy: 0.7770\n",
      "Epoch 323/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 3.8278 - val_accuracy: 0.7786\n",
      "Epoch 324/512\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 3.7342 - val_accuracy: 0.7796\n",
      "Epoch 325/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 3.7643 - val_accuracy: 0.7834\n",
      "Epoch 326/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 3.7323 - val_accuracy: 0.7786\n",
      "Epoch 327/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 3.7549 - val_accuracy: 0.7800\n",
      "Epoch 328/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 3.7328 - val_accuracy: 0.7776\n",
      "Epoch 329/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0383 - accuracy: 0.9886 - val_loss: 3.8177 - val_accuracy: 0.7798\n",
      "Epoch 330/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 3.8386 - val_accuracy: 0.7794\n",
      "Epoch 331/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 3.6610 - val_accuracy: 0.7820\n",
      "Epoch 332/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 3.6872 - val_accuracy: 0.7754\n",
      "Epoch 333/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 3.7131 - val_accuracy: 0.7776\n",
      "Epoch 334/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 3.8461 - val_accuracy: 0.7818\n",
      "Epoch 335/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 4.1192 - val_accuracy: 0.7722\n",
      "Epoch 336/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0405 - accuracy: 0.9875 - val_loss: 4.0014 - val_accuracy: 0.7726\n",
      "Epoch 337/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 3.9185 - val_accuracy: 0.7750\n",
      "Epoch 338/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 3.9801 - val_accuracy: 0.7762\n",
      "Epoch 339/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0385 - accuracy: 0.9885 - val_loss: 3.8878 - val_accuracy: 0.7766\n",
      "Epoch 340/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 3.8408 - val_accuracy: 0.7776\n",
      "Epoch 341/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 3.9780 - val_accuracy: 0.7774\n",
      "Epoch 342/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 3.9521 - val_accuracy: 0.7732\n",
      "Epoch 343/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 3.8841 - val_accuracy: 0.7734\n",
      "Epoch 344/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 3.7793 - val_accuracy: 0.7758\n",
      "Epoch 345/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 3.7735 - val_accuracy: 0.7708\n",
      "Epoch 346/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 3.8383 - val_accuracy: 0.7726\n",
      "Epoch 347/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 3.8861 - val_accuracy: 0.7786\n",
      "Epoch 348/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 3.9360 - val_accuracy: 0.7758\n",
      "Epoch 349/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 3.7634 - val_accuracy: 0.7794\n",
      "Epoch 350/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 3.7902 - val_accuracy: 0.7786\n",
      "Epoch 351/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 3.7826 - val_accuracy: 0.7828\n",
      "Epoch 352/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 3.7792 - val_accuracy: 0.7746\n",
      "Epoch 353/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 3.7268 - val_accuracy: 0.7798\n",
      "Epoch 354/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 3.8247 - val_accuracy: 0.7794\n",
      "Epoch 355/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0352 - accuracy: 0.9886 - val_loss: 3.7983 - val_accuracy: 0.7796\n",
      "Epoch 356/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0384 - accuracy: 0.9888 - val_loss: 3.9615 - val_accuracy: 0.7808\n",
      "Epoch 357/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 3.9319 - val_accuracy: 0.7800\n",
      "Epoch 358/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 4.0642 - val_accuracy: 0.7768\n",
      "Epoch 359/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0361 - accuracy: 0.9891 - val_loss: 3.8057 - val_accuracy: 0.7788\n",
      "Epoch 360/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 3.9105 - val_accuracy: 0.7802\n",
      "Epoch 361/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0321 - accuracy: 0.9894 - val_loss: 3.9215 - val_accuracy: 0.7804\n",
      "Epoch 362/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 3.9898 - val_accuracy: 0.7744\n",
      "Epoch 363/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0365 - accuracy: 0.9891 - val_loss: 3.8542 - val_accuracy: 0.7774\n",
      "Epoch 364/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 3.9072 - val_accuracy: 0.7826\n",
      "Epoch 365/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 3.9728 - val_accuracy: 0.7766\n",
      "Epoch 366/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 3.9121 - val_accuracy: 0.7790\n",
      "Epoch 367/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0370 - accuracy: 0.9888 - val_loss: 3.9176 - val_accuracy: 0.7766\n",
      "Epoch 368/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 3.8894 - val_accuracy: 0.7804\n",
      "Epoch 369/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0359 - accuracy: 0.9891 - val_loss: 3.9429 - val_accuracy: 0.7796\n",
      "Epoch 370/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 3.9021 - val_accuracy: 0.7782\n",
      "Epoch 371/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 3.9859 - val_accuracy: 0.7758\n",
      "Epoch 372/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 3.9478 - val_accuracy: 0.7770\n",
      "Epoch 373/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 3.9254 - val_accuracy: 0.7790\n",
      "Epoch 374/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 3.8628 - val_accuracy: 0.7768\n",
      "Epoch 375/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 3.9047 - val_accuracy: 0.7814\n",
      "Epoch 376/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0412 - accuracy: 0.9880 - val_loss: 3.8670 - val_accuracy: 0.7786\n",
      "Epoch 377/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 4.0065 - val_accuracy: 0.7742\n",
      "Epoch 378/512\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0401 - accuracy: 0.9886 - val_loss: 3.8835 - val_accuracy: 0.7730\n",
      "Epoch 379/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 3.9229 - val_accuracy: 0.7760\n",
      "Epoch 380/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 3.9165 - val_accuracy: 0.7766\n",
      "Epoch 381/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 3.9030 - val_accuracy: 0.7762\n",
      "Epoch 382/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 3.9646 - val_accuracy: 0.7798\n",
      "Epoch 383/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0413 - accuracy: 0.9883 - val_loss: 3.9682 - val_accuracy: 0.7740\n",
      "Epoch 384/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 4.1113 - val_accuracy: 0.7812\n",
      "Epoch 385/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 4.1086 - val_accuracy: 0.7706\n",
      "Epoch 386/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 4.0610 - val_accuracy: 0.7802\n",
      "Epoch 387/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 4.0246 - val_accuracy: 0.7758\n",
      "Epoch 388/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 4.1101 - val_accuracy: 0.7752\n",
      "Epoch 389/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 4.0745 - val_accuracy: 0.7772\n",
      "Epoch 390/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 4.1097 - val_accuracy: 0.7776\n",
      "Epoch 391/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0396 - accuracy: 0.9885 - val_loss: 4.0902 - val_accuracy: 0.7802\n",
      "Epoch 392/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 4.0834 - val_accuracy: 0.7748\n",
      "Epoch 393/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 4.1769 - val_accuracy: 0.7774\n",
      "Epoch 394/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0374 - accuracy: 0.9889 - val_loss: 4.1523 - val_accuracy: 0.7730\n",
      "Epoch 395/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0361 - accuracy: 0.9893 - val_loss: 4.2356 - val_accuracy: 0.7766\n",
      "Epoch 396/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 4.1286 - val_accuracy: 0.7780\n",
      "Epoch 397/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 4.1568 - val_accuracy: 0.7784\n",
      "Epoch 398/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 3.8925 - val_accuracy: 0.7812\n",
      "Epoch 399/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 4.1050 - val_accuracy: 0.7764\n",
      "Epoch 400/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 4.1225 - val_accuracy: 0.7728\n",
      "Epoch 401/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 4.2168 - val_accuracy: 0.7786\n",
      "Epoch 402/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 4.3603 - val_accuracy: 0.7774\n",
      "Epoch 403/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 4.0867 - val_accuracy: 0.7798\n",
      "Epoch 404/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 4.1407 - val_accuracy: 0.7764\n",
      "Epoch 405/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 4.2800 - val_accuracy: 0.7736\n",
      "Epoch 406/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 4.1438 - val_accuracy: 0.7800\n",
      "Epoch 407/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0386 - accuracy: 0.9891 - val_loss: 4.1342 - val_accuracy: 0.7796\n",
      "Epoch 408/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 4.1778 - val_accuracy: 0.7770\n",
      "Epoch 409/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 4.1850 - val_accuracy: 0.7750\n",
      "Epoch 410/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 4.4558 - val_accuracy: 0.7718\n",
      "Epoch 411/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 4.2114 - val_accuracy: 0.7780\n",
      "Epoch 412/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 4.2518 - val_accuracy: 0.7750\n",
      "Epoch 413/512\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 4.1252 - val_accuracy: 0.7840\n",
      "Epoch 414/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 4.3475 - val_accuracy: 0.7786\n",
      "Epoch 415/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 4.3403 - val_accuracy: 0.7754\n",
      "Epoch 416/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 4.1588 - val_accuracy: 0.7806\n",
      "Epoch 417/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 4.2095 - val_accuracy: 0.7808\n",
      "Epoch 418/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 4.2949 - val_accuracy: 0.7808\n",
      "Epoch 419/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 4.2000 - val_accuracy: 0.7824\n",
      "Epoch 420/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 4.4323 - val_accuracy: 0.7732\n",
      "Epoch 421/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 4.2696 - val_accuracy: 0.7744\n",
      "Epoch 422/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 4.3399 - val_accuracy: 0.7798\n",
      "Epoch 423/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0392 - accuracy: 0.9886 - val_loss: 4.3859 - val_accuracy: 0.7742\n",
      "Epoch 424/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 4.4090 - val_accuracy: 0.7726\n",
      "Epoch 425/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0361 - accuracy: 0.9895 - val_loss: 4.3388 - val_accuracy: 0.7824\n",
      "Epoch 426/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 4.3552 - val_accuracy: 0.7800\n",
      "Epoch 427/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 4.3704 - val_accuracy: 0.7736\n",
      "Epoch 428/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 4.4819 - val_accuracy: 0.7756\n",
      "Epoch 429/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 4.4793 - val_accuracy: 0.7720\n",
      "Epoch 430/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0349 - accuracy: 0.9897 - val_loss: 4.5429 - val_accuracy: 0.7716\n",
      "Epoch 431/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 4.4733 - val_accuracy: 0.7716\n",
      "Epoch 432/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0385 - accuracy: 0.9892 - val_loss: 4.4596 - val_accuracy: 0.7704\n",
      "Epoch 433/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0359 - accuracy: 0.9899 - val_loss: 4.4664 - val_accuracy: 0.7724\n",
      "Epoch 434/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 4.4649 - val_accuracy: 0.7738\n",
      "Epoch 435/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0388 - accuracy: 0.9889 - val_loss: 4.4571 - val_accuracy: 0.7686\n",
      "Epoch 436/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 4.5292 - val_accuracy: 0.7772\n",
      "Epoch 437/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 4.5817 - val_accuracy: 0.7700\n",
      "Epoch 438/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 4.3386 - val_accuracy: 0.7736\n",
      "Epoch 439/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 4.3542 - val_accuracy: 0.7764\n",
      "Epoch 440/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0354 - accuracy: 0.9898 - val_loss: 4.3249 - val_accuracy: 0.7754\n",
      "Epoch 441/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 4.2901 - val_accuracy: 0.7734\n",
      "Epoch 442/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 4.4393 - val_accuracy: 0.7710\n",
      "Epoch 443/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0386 - accuracy: 0.9891 - val_loss: 4.4310 - val_accuracy: 0.7736\n",
      "Epoch 444/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 4.3763 - val_accuracy: 0.7750\n",
      "Epoch 445/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0325 - accuracy: 0.9903 - val_loss: 4.5332 - val_accuracy: 0.7768\n",
      "Epoch 446/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 4.5716 - val_accuracy: 0.7714\n",
      "Epoch 447/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0367 - accuracy: 0.9892 - val_loss: 4.4468 - val_accuracy: 0.7766\n",
      "Epoch 448/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 4.5678 - val_accuracy: 0.7746\n",
      "Epoch 449/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 4.5921 - val_accuracy: 0.7706\n",
      "Epoch 450/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 4.5942 - val_accuracy: 0.7750\n",
      "Epoch 451/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 4.4116 - val_accuracy: 0.7760\n",
      "Epoch 452/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 4.6681 - val_accuracy: 0.7742\n",
      "Epoch 453/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 4.7221 - val_accuracy: 0.7686\n",
      "Epoch 454/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 4.5705 - val_accuracy: 0.7776\n",
      "Epoch 455/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0341 - accuracy: 0.9899 - val_loss: 4.3949 - val_accuracy: 0.7758\n",
      "Epoch 456/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 4.7715 - val_accuracy: 0.7738\n",
      "Epoch 457/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 4.5559 - val_accuracy: 0.7730\n",
      "Epoch 458/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 4.5822 - val_accuracy: 0.7712\n",
      "Epoch 459/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 4.6360 - val_accuracy: 0.7718\n",
      "Epoch 460/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 4.6350 - val_accuracy: 0.7736\n",
      "Epoch 461/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 4.4873 - val_accuracy: 0.7738\n",
      "Epoch 462/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 4.6185 - val_accuracy: 0.7694\n",
      "Epoch 463/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 4.3676 - val_accuracy: 0.7758\n",
      "Epoch 464/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 4.5366 - val_accuracy: 0.7700\n",
      "Epoch 465/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 4.7989 - val_accuracy: 0.7704\n",
      "Epoch 466/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 4.6911 - val_accuracy: 0.7742\n",
      "Epoch 467/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 4.5431 - val_accuracy: 0.7756\n",
      "Epoch 468/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0348 - accuracy: 0.9899 - val_loss: 4.5258 - val_accuracy: 0.7722\n",
      "Epoch 469/512\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 4.5798 - val_accuracy: 0.7682\n",
      "Epoch 470/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 4.5911 - val_accuracy: 0.7740\n",
      "Epoch 471/512\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 4.5945 - val_accuracy: 0.7778\n",
      "Epoch 472/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 4.7183 - val_accuracy: 0.7724\n",
      "Epoch 473/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 4.6588 - val_accuracy: 0.7766\n",
      "Epoch 474/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0367 - accuracy: 0.9892 - val_loss: 4.6117 - val_accuracy: 0.7772\n",
      "Epoch 475/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 4.5819 - val_accuracy: 0.7772\n",
      "Epoch 476/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0367 - accuracy: 0.9891 - val_loss: 4.5692 - val_accuracy: 0.7774\n",
      "Epoch 477/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0319 - accuracy: 0.9905 - val_loss: 4.7127 - val_accuracy: 0.7716\n",
      "Epoch 478/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 4.7765 - val_accuracy: 0.7790\n",
      "Epoch 479/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 4.6744 - val_accuracy: 0.7764\n",
      "Epoch 480/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 4.5531 - val_accuracy: 0.7780\n",
      "Epoch 481/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 4.6116 - val_accuracy: 0.7732\n",
      "Epoch 482/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 4.8639 - val_accuracy: 0.7736\n",
      "Epoch 483/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0410 - accuracy: 0.9891 - val_loss: 4.7219 - val_accuracy: 0.7742\n",
      "Epoch 484/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0364 - accuracy: 0.9897 - val_loss: 4.5947 - val_accuracy: 0.7790\n",
      "Epoch 485/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 4.6820 - val_accuracy: 0.7742\n",
      "Epoch 486/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0320 - accuracy: 0.9907 - val_loss: 4.7046 - val_accuracy: 0.7788\n",
      "Epoch 487/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 4.7674 - val_accuracy: 0.7748\n",
      "Epoch 488/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 4.5195 - val_accuracy: 0.7770\n",
      "Epoch 489/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 4.6221 - val_accuracy: 0.7764\n",
      "Epoch 490/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 4.7737 - val_accuracy: 0.7794\n",
      "Epoch 491/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 4.7250 - val_accuracy: 0.7790\n",
      "Epoch 492/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0333 - accuracy: 0.9906 - val_loss: 4.7547 - val_accuracy: 0.7766\n",
      "Epoch 493/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 4.5356 - val_accuracy: 0.7778\n",
      "Epoch 494/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 4.5739 - val_accuracy: 0.7760\n",
      "Epoch 495/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 4.5999 - val_accuracy: 0.7720\n",
      "Epoch 496/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 4.5566 - val_accuracy: 0.7764\n",
      "Epoch 497/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0348 - accuracy: 0.9905 - val_loss: 4.6599 - val_accuracy: 0.7754\n",
      "Epoch 498/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 4.7978 - val_accuracy: 0.7786\n",
      "Epoch 499/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 4.7542 - val_accuracy: 0.7738\n",
      "Epoch 500/512\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 4.5891 - val_accuracy: 0.7806\n",
      "Epoch 501/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 4.7051 - val_accuracy: 0.7754\n",
      "Epoch 502/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 4.5738 - val_accuracy: 0.7808\n",
      "Epoch 503/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 4.8120 - val_accuracy: 0.7746\n",
      "Epoch 504/512\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 4.6703 - val_accuracy: 0.7736\n",
      "Epoch 505/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0367 - accuracy: 0.9901 - val_loss: 4.5835 - val_accuracy: 0.7792\n",
      "Epoch 506/512\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 4.8735 - val_accuracy: 0.7748\n",
      "Epoch 507/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0366 - accuracy: 0.9899 - val_loss: 5.0184 - val_accuracy: 0.7714\n",
      "Epoch 508/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 4.7373 - val_accuracy: 0.7738\n",
      "Epoch 509/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 4.7927 - val_accuracy: 0.7756\n",
      "Epoch 510/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0345 - accuracy: 0.9905 - val_loss: 4.7933 - val_accuracy: 0.7712\n",
      "Epoch 511/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 5.0638 - val_accuracy: 0.7750\n",
      "Epoch 512/512\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0397 - accuracy: 0.9898 - val_loss: 4.8278 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b38c6ed580>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "EPOCHS = 512\n",
    "\n",
    "model.fit(train_data, validation_data=val_data, epochs = EPOCHS, use_multiprocessing=True, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\VS-Code\\Applied-Neural-Networks\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('connect4_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/79 [..............................] - ETA: 1s - loss: 6.1705 - accuracy: 0.7031"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 4.3769 - accuracy: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.3769402503967285, 0.7979999780654907]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "class connect_x:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.board_height = 6\n",
    "        self.board_width = 7\n",
    "        self.board_state = np.zeros([self.board_height, self.board_width], dtype=np.int8)\n",
    "        self.players = {'p1': 1, 'p2': -1}\n",
    "        self.isDone = False\n",
    "        self.reward = {'win': 1, 'draw': 0.5, 'lose': -1}\n",
    "    \n",
    "    def render(self):\n",
    "        rendered_board_state = self.board_state.copy().astype(str)\n",
    "        rendered_board_state[self.board_state == 0] = ' '\n",
    "        rendered_board_state[self.board_state == 1] = 'O'\n",
    "        rendered_board_state[self.board_state == -1] = 'X'\n",
    "        display(pd.DataFrame(rendered_board_state))\n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "        \n",
    "    def get_available_actions(self):\n",
    "        available_cols = []\n",
    "        for j in range(self.board_width):\n",
    "            if np.sum([self.board_state[:, j] == 0]) != 0:\n",
    "                available_cols.append(j)\n",
    "        return available_cols\n",
    "    \n",
    "    def check_game_done(self, player):\n",
    "        if player == 'p1':\n",
    "            check = '1 1 1 1'\n",
    "        else:\n",
    "            check = '-1 -1 -1 -1'\n",
    "        \n",
    "        # check vertically then horizontally\n",
    "        for j in range(self.board_width):\n",
    "            if check in str(self.board_state[:, j]):\n",
    "                self.isDone = True\n",
    "        for i in range(self.board_height):\n",
    "            if check in str(self.board_state[i, :]):\n",
    "                self.isDone = True\n",
    "        \n",
    "        # check left diagonal and right diagonal\n",
    "        for k in range(0, self.board_height - 4 + 1):\n",
    "            left_diagonal = np.array([self.board_state[k + d, d] for d in \\\n",
    "                            range(min(self.board_height - k, min(self.board_height, self.board_width)))])\n",
    "            right_diagonal = np.array([self.board_state[d + k, self.board_width - d - 1] for d in \\\n",
    "                            range(min(self.board_height - k, min(self.board_height, self.board_width)))])\n",
    "            if check in str(left_diagonal) or check in str(right_diagonal):\n",
    "                self.isDone = True\n",
    "        for k in range(1, self.board_width - 4 + 1):\n",
    "            left_diagonal = np.array([self.board_state[d, d + k] for d in \\\n",
    "                            range(min(self.board_width - k, min(self.board_height, self.board_width)))])\n",
    "            right_diagonal = np.array([self.board_state[d, self.board_width - 1 - k - d] for d in \\\n",
    "                            range(min(self.board_width - k, min(self.board_height, self.board_width)))])\n",
    "            if check in str(left_diagonal) or check in str(right_diagonal):\n",
    "                self.isDone = True\n",
    "        \n",
    "        if self.isDone:\n",
    "            return self.reward['win']\n",
    "        # check for draw\n",
    "        elif np.sum([self.board_state == 0]) == 0:\n",
    "            self.isDone = True\n",
    "            return self.reward['draw']\n",
    "        else:\n",
    "            return 0.\n",
    "        \n",
    "    def make_move(self, a, player):\n",
    "        # check if move is valid\n",
    "        if a in self.get_available_actions():\n",
    "            i = np.sum([self.board_state[:, a] == 0]) - 1\n",
    "            self.board_state[i, a] = self.players[player]\n",
    "        else:\n",
    "            print('Move is invalid')\n",
    "            self.render()\n",
    "\n",
    "        reward = self.check_game_done(player)\n",
    "        \n",
    "        # give feedback as new state and reward\n",
    "        return self.board_state.copy(), reward\n",
    "\n",
    "env = connect_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0, -1,  0,  0,  0],\n",
       "        [ 0,  0,  0, -1,  0,  0,  0],\n",
       "        [ 0,  0,  0, -1,  0,  0,  0],\n",
       "        [ 0,  0,  0, -1,  0,  0,  0]], dtype=int8),\n",
       " 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.make_move(3,'p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  1  1  0  0]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1 -1  0  1  1  1  0]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1 -1  1  1  1  1 -1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mboard_state)\n\u001b[1;32m----> 9\u001b[0m env\u001b[38;5;241m.\u001b[39mmake_move(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnter your move: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "state = env.board_state.copy().reshape(1, 6, 7, 1)\n",
    "reward = 0\n",
    "while reward != 1:\n",
    "    action = np.argmax(model.predict(state))\n",
    "    state, reward = env.make_move(action, 'p1')\n",
    "    state = state.reshape(1, 6, 7, 1)\n",
    "    print(env.board_state)\n",
    "    env.make_move(int(input('Enter your move: ')), 'p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 209ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.5384244e-17, 1.4368956e-36, 2.4640730e-26, 1.0000000e+00,\n",
       "        2.0217451e-29, 6.0259550e-26, 3.1349790e-18]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
